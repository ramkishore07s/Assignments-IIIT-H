{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import random\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TrigramLanguageModel import TrigramLanguageModel, null_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START = '<s>'\n",
    "STOP = '<st>'\n",
    "TERMINAL_POS = 'TER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for HMM\n",
    "* `Emission_model(<o1>, <q2>, <o2>) = P(o2 | o1, q2)`\n",
    "* `POS_model(<q1>, <q2>, <q3>) = P(q3 | q2, q1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_model = TrigramLanguageModel(null_tokenizer)\n",
    "Emission_model = TrigramLanguageModel(null_tokenizer)\n",
    "possible_tags = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ = len(brown.tagged_sents()) * 0.8\n",
    "train = brown.tagged_sents()[0:int(train_)]\n",
    "dev_ = brown.tagged_sents()[int(train_):]\n",
    "dev = brown.tagged_sents()[int(train_):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_in(sentence): return [(START, TERMINAL_POS), (START, TERMINAL_POS)] + sentence + [(STOP, TERMINAL_POS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Building POS, Emission  models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in train:\n",
    "    sentence = fill_in(sentence)\n",
    "    for i in range(2, len(sentence)): POS_model.update_tree([sentence[i-2][1], sentence[i-1][1], sentence[i][1]])\n",
    "    for i in range(1, len(sentence)): Emission_model.update_tree([sentence[i-1][0], sentence[i][1], sentence[i][0]])\n",
    "    for w, p in sentence:\n",
    "        if w in possible_tags: \n",
    "            if p not in possible_tags[w]:\n",
    "                possible_tags[w].append(p)\n",
    "        else: possible_tags[w] = [p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Viterbi():\n",
    "    def __init__(self, POS_model, Emission_model, possible_tags):\n",
    "        self.Q_model = POS_model\n",
    "        self.O_model = Emission_model\n",
    "        self.Q = list(POS_model.tree.keys())\n",
    "        self.states = None\n",
    "        self.sentence = None\n",
    "        self.observations = None\n",
    "        self.__cache = {}\n",
    "        self.Q_ = possible_tags\n",
    "        \n",
    "    def __call__(self, sentence):\n",
    "        for word in sentence:\n",
    "            if not word in self.Q_:\n",
    "                self.Q_[word] = self.Q\n",
    "        self.states = None\n",
    "        self.sentence = None\n",
    "        self.observations = None\n",
    "        self.__cache = {}\n",
    "        self.states = None\n",
    "        self.observations = self.__fill_in(sentence)\n",
    "        self.r()\n",
    "        self.get_pos()\n",
    "        \n",
    "        return self.states\n",
    "    \n",
    "    def __fill_in(self, sentence):\n",
    "        return [START, START] + sentence + [STOP]\n",
    "    \n",
    "    def __r(self, n, position):\n",
    "        if position > 3: # for both n-1 and n-2\n",
    "            qn = self.Q_[self.observations[position]][n]\n",
    "            for q1 in self.Q_[self.observations[position-1]]:\n",
    "                arr = []\n",
    "                for q2 in self.Q_[self.observations[position-2]]:\n",
    "                    cur_prob = self.Q_model.get_prob([q2, q1, qn])\n",
    "                    cur_prob *= self.O_model.get_prob([self.observations[position-2], q1 , self.observations[position-1]])\n",
    "                    cur_prob *= self.__cache[position-1][q1][q2]\n",
    "                    arr.append(cur_prob)\n",
    "                self.__cache_probs(position, qn, q1, max(arr))\n",
    "                    \n",
    "        else: # only for n-1, q1 and q0 are constants\n",
    "            max_q = None\n",
    "            max_prob = 0\n",
    "            q3 = self.Q_[self.observations[position]][n]\n",
    "            o1, o2 = self.observations[1:3]\n",
    "            for q2 in self.Q_[self.observations[position - 1]]:\n",
    "                cur_prob = self.Q_model.get_prob([TERMINAL_POS, q2, q3])\n",
    "                cur_prob *= self.O_model.get_prob([o1, q2 , o2])\n",
    "                cur_prob *= self.Q_model.get_prob([TERMINAL_POS, TERMINAL_POS, q2])\n",
    "                self.__cache_probs(position, q3, q2, cur_prob)\n",
    "#                print(self.__cache)\n",
    "                \n",
    "    def __cache_probs(self, position, cur_pos, cur_his, prob):\n",
    "        # position, current pos, prev two pos, prob\n",
    "        if position not in self.__cache: self.__cache[position] = {}\n",
    "        if cur_pos not in self.__cache[position]: self.__cache[position][cur_pos] = {}\n",
    "        if cur_his not in self.__cache[position][cur_pos]: self.__cache[position][cur_pos][cur_his] = prob\n",
    "        \n",
    "    def r(self):\n",
    "        for position in range(3, len(self.observations)):\n",
    "            for n in range(len(self.Q_[self.observations[position]])): #for each q for each position cache probability based on q-1 and q-2\n",
    "                self.__r(n, position)\n",
    "            \n",
    "    def get_pos(self):\n",
    "        a = self.__cache\n",
    "        top = len(a) + 2\n",
    "        cur = 'TER'\n",
    "        states = []\n",
    "        while(top > 2):\n",
    "            max_k, max_v = None, -1\n",
    "            for i in a[top][cur]:\n",
    "                if a[top][cur][i] > max_v:\n",
    "                    max_v = a[top][cur][i]\n",
    "                    max_k = i\n",
    "            states.append(max_k)\n",
    "            cur = max_k\n",
    "            top -= 1\n",
    "        self.states =  ['TER', 'TER'] + states[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = Viterbi(POS_model, Emission_model, possible_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on first 500 sentences from held-out Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\r"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "count = 0\n",
    "for i in dev[0:500]:\n",
    "    print(count, end='\\r')\n",
    "    count += 1\n",
    "    sentence, tags = list(zip(*i))\n",
    "    try:\n",
    "        pred = v(list(sentence))[2:-1]\n",
    "        for i, j in zip(pred, list(tags)):\n",
    "            if i == j: a += 1\n",
    "            b += 1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Held out accuracy on first 500 sentences: 92.38488783943329%\n"
     ]
    }
   ],
   "source": [
    "print('Held out accuracy on first 500 sentences: ' +  str(float(a)/b * 100 ) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Forward():\n",
    "    def __init__(self, POS_model, Emission_model, possible_tags):\n",
    "        self.Q_model = POS_model\n",
    "        self.O_model = Emission_model\n",
    "        self.Q = list(POS_model.tree.keys())\n",
    "        self.states = None\n",
    "        self.observations = None\n",
    "        self.__cache = {}\n",
    "        self.sentence = None\n",
    "        self.Q_ = possible_tags\n",
    "        \n",
    "    def __call__(self, sentence):\n",
    "        for word in sentence:\n",
    "            if not word in self.Q_:\n",
    "                self.Q_[word] = self.Q\n",
    "        self.observations = [START, START] + list(sentence) + [STOP]\n",
    "        self.sentence = sentence\n",
    "        self.p_ = []\n",
    "        self.p()\n",
    "        \n",
    "        return self.get_prob()\n",
    "    \n",
    "    def cache_prob(self, q, q1, n, prob):\n",
    "        if n not in self.__cache: self.__cache[n] = {}\n",
    "        if q not in self.__cache[n]: self.__cache[n][q] = {}\n",
    "        self.__cache[n][q][q1] = prob\n",
    "        \n",
    "    def get_prob(self):\n",
    "        f = len(self.observations) - 1\n",
    "        p = 0.0\n",
    "        for i in self.__cache[f]:\n",
    "            for j in self.__cache[f][i]:\n",
    "                p += self.__cache[f][i][j]\n",
    "        return p\n",
    "        \n",
    "    def __p(self, q, n):\n",
    "        if n > 2:\n",
    "            prob = 0.0\n",
    "            for q1 in self.Q_[self.observations[n-1]]:\n",
    "                for q2 in self.Q_[self.observations[n-2]]:\n",
    "                    temp = self.Q_model.get_prob([q2, q1, q]) \n",
    "                    temp *= self.__cache[n-1][q1][q2] \n",
    "                    temp *= self.O_model.get_prob([self.observations[n-2], q1, self.observations[n-1]])\n",
    "                    prob += temp\n",
    "                self.cache_prob(q, q1, n, prob)\n",
    "            \n",
    "        else:\n",
    "            for q1 in self.Q_[self.observations[n-1]]:\n",
    "                temp = self.Q_model.get_prob([TERMINAL_POS, q1, q])\n",
    "                temp *= self.O_model.get_prob([self.observations[n-2], q1, self.observations[n-1]])\n",
    "                prob = temp\n",
    "                self.cache_prob(q, q1, n, prob)\n",
    "            \n",
    "    def p(self):\n",
    "        for n in range(2, len(self.observations)):\n",
    "            for q in self.Q_[self.observations[n]]:\n",
    "                self.__p(q, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = Forward(POS_model, Emission_model, possible_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train probability is: 0.013157183104485501\n"
     ]
    }
   ],
   "source": [
    "avg_train_prob = 0\n",
    "for i in train[0:500]:\n",
    "    try: avg_train_prob += f(list(zip(*i))[0])\n",
    "    except: pass\n",
    "avg_train_prob /= 500.\n",
    "print('Average train probability is:', avg_train_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avg probability for dev set is relatively low because dev set has some previously unseen words, for which the Emission probabilities and State Transition probabilities are very low**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average dev probability is: 0.00011150557999454281\n"
     ]
    }
   ],
   "source": [
    "avg_dev_prob = 0\n",
    "for i in dev[0:500]:\n",
    "    try: avg_dev_prob += f(list(zip(*i))[0])\n",
    "    except: pass\n",
    "avg_dev_prob /= 500.\n",
    "print('Average dev probability is:', avg_dev_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
